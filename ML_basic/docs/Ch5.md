# 결정 트리
*수학적인 부분에 대한 보충이 필요  
결정 트리는 분류 문제에 사용되는 트리 형태의 모델이다.  
조건을 기반으로 주어진 데이터를 단계적으로 분류한다.  
특정 제약을 만족하는 방식으로 조건을 설정한다.  
결정 트리는 다른 모델들에 비해 설명력이 좋다는 특징이 있다.  
결정 트리는 따로 normalize할 필요가 없다.  

## 결정 트리의 깊이 제한
결정 트리의 깊이는 max_depth함수로 제한할 수 있다.  
깊이가 너무 깊어질 경우 과적합의 위험이 있다.  

## 불순도
일반적으로 "불순도"라는 값과 관련된 어떤 값을 최소화하는 방향으로 결정 트리의 조건문을 만들게 된다.  
대표적인 "불순도"는 지니 불순도(gini impurity)이다. 지니 계수라고도 부른다.  
$gini = 1 - ((N_{pos} / N)^2 + (N_{neg} / N)^2)$  

정보 이득은 부모와 자식 노드 사이의 불순도 차이를 의미한다.  
일반적으로 정보 이득을 최대화(부모 노드의 불순도가 자식 노드보다 가능한 크게) 하는 방향으로 트리 구축이 이루어진다.  

지니 불순도 대신 정보 엔트로피를 사용하기도 한다.

# 교차 검증과 그리드 서치
## 교차 검증
일반적으로 데이터셋을 train - validation - test로 나누어 검증을 하게 된다.  
cross validation은 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있게 해준다.  
cross validation은 train set과 validation set의 비율만 정해놓고 이것을 만족하는 범위 내에서 다양하게 분할해 모두 시도한다.  

## 그리드 서치
가능한 hyperparameter조합 쌍들 만들고 다 시도해 보는 것 의미.  
그냥 도식화 했을 떄 그리드와 비슷한 형태여서 그리드 서치라고 부르는 것 같다.  

# 트리의 앙상블
트리를 하나만 사용하면 과적합의 문제가 발생하기 쉽다.  
트리의 앙상블을 사용해 이것을 개선할 수 있다.  

트리의 앙상블 방법은 다음과 같다.
- 랜덤 포레스트
- 엑스트라 트리

## 랜덤 포레스트
부트스트랩 셈플을 사용한다.  
부트스트랩 셈플을 사용한다는 것은 가지고 있는 데이터셋에서 복원 추출을 해 샘플을 만든다는 의미이다.

부트스트랩 샘플을 사용해 트리를 각각 학습하고 그것들을 조합해 결과를 도출하는 방식을 랜덤 포레스트라고 한다.

## 엑스트라 트리
랜덤 포레스트가 샘플을 바꾸었다면 엑스트라 트리는 분할에 사용할 특성을 무작위로 선택한다.

## 그라디언트 부스팅
그라디언트 부스팅은 깊이가 얕은 결정 트리를 사용해 이전 트리의 오차를 보완하는 방식으로 앙상블을 진행한다.  
Gradient Descent를 사용해 트리를 앙상블에 추가한다. 분류에는 로지스틱 손실 함수를 사용하고 회귀에서는 MSE를 사용한다.  

히스토그램 기반 그라디언트 부스팅이라는 알고리즘도 있다.  